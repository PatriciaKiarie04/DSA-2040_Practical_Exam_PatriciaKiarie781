{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb7fbfb",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdafec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def extract(data_source='C:\\\\Users\\\\flags\\\\End-sem DSA 2040\\\\DSA-2040_Practical_Exam_PatriciaKiarie781\\\\Data Warehousing\\\\ETL_Process\\\\raw\\\\Online Retail.xlsx'):\n",
    "    \"\"\"\n",
    "    Extracts data from an Excel file into a pandas DataFrame.\n",
    "    Handles missing values, data type conversions, and basic data validation.\n",
    "    \n",
    "    Args:\n",
    "        data_source (str): Path to the Excel file containing retail data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame or None: Cleaned DataFrame if successful, None if extraction fails\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Extraction Phase ---\")\n",
    "    \n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        df_raw = pd.read_excel(data_source)\n",
    "        print(f\"Data extracted from {data_source}. Total rows: {len(df_raw)}\")\n",
    "        \n",
    "        # Basic data validation\n",
    "        required_columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', \n",
    "                          'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']\n",
    "        missing_columns = [col for col in required_columns if col not in df_raw.columns]\n",
    "        if missing_columns:\n",
    "            print(f\"Error: Missing required columns: {missing_columns}\")\n",
    "            return None\n",
    "            \n",
    "        # Handle missing values\n",
    "        print(\"\\nMissing values before cleaning:\")\n",
    "        print(df_raw.isnull().sum())\n",
    "        \n",
    "        # Drop rows with missing CustomerID as it's crucial for the customer dimension\n",
    "        df_raw.dropna(subset=['CustomerID'], inplace=True)\n",
    "        \n",
    "        # Fill missing values for other columns\n",
    "        df_raw['Description'].fillna('Unknown Product', inplace=True)\n",
    "        df_raw['Country'].fillna('Unknown', inplace=True)\n",
    "        \n",
    "        # Convert data types\n",
    "        df_raw['CustomerID'] = df_raw['CustomerID'].astype(int)\n",
    "        df_raw['InvoiceDate'] = pd.to_datetime(df_raw['InvoiceDate'])\n",
    "        df_raw['UnitPrice'] = pd.to_numeric(df_raw['UnitPrice'], errors='coerce')\n",
    "        df_raw['Quantity'] = pd.to_numeric(df_raw['Quantity'], errors='coerce')\n",
    "        \n",
    "        # Remove rows with invalid numeric values\n",
    "        df_raw.dropna(subset=['UnitPrice', 'Quantity'], inplace=True)\n",
    "        \n",
    "        print(\"\\nMissing values after cleaning:\")\n",
    "        print(df_raw.isnull().sum())\n",
    "        print(f\"\\nFinal row count: {len(df_raw)}\")\n",
    "        print(\"\\nData types of columns:\")\n",
    "        print(df_raw.dtypes)\n",
    "        \n",
    "        print(\"\\nExtraction complete.\")\n",
    "        return df_raw\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Excel file '{data_source}' not found. Please ensure the file is in the correct directory.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data extraction: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c309da",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e53f85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df_raw):\n",
    "    \"\"\"\n",
    "    Transforms the raw data by cleaning, filtering, and creating new columns/tables.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Transformation Phase ---\")\n",
    "\n",
    "    # Handle outliers by removing rows where Quantity < 0 or UnitPrice <= 0.\n",
    "    df_cleaned = df_raw[(df_raw['Quantity'] > 0) & (df_raw['UnitPrice'] > 0)].copy()\n",
    "    print(f\"Cleaned data. Removed {len(df_raw) - len(df_cleaned)} rows with invalid quantity or price.\")\n",
    "\n",
    "    # Calculate the new 'TotalSales' column.\n",
    "    df_cleaned['TotalSales'] = df_cleaned['Quantity'] * df_cleaned['UnitPrice']\n",
    "    print(f\"Created 'TotalSales' column. New row count: {len(df_cleaned)}\")\n",
    "    \n",
    "    # Filter the data for sales in the last year, assuming a current date of August 12, 2025.\n",
    "    current_date = datetime(2025, 8, 12)\n",
    "    one_year_ago = current_date - timedelta(days=365)\n",
    "    df_filtered = df_cleaned[df_cleaned['InvoiceDate'] >= one_year_ago].copy()\n",
    "    print(f\"Filtered for the last year. Rows remaining: {len(df_filtered)}\")\n",
    "    \n",
    "    # Sort by InvoiceDate to prepare for creating the Time Dimension.\n",
    "    df_filtered.sort_values('InvoiceDate', inplace=True)\n",
    "    \n",
    "    # Create the Customer Dimension table.\n",
    "    customer_dim = df_filtered.groupby('CustomerID').agg(\n",
    "        total_purchases=('TotalSales', 'sum'),\n",
    "        country=('Country', lambda x: x.mode()[0] if not x.mode().empty else None)\n",
    "    ).reset_index()\n",
    "    customer_dim['customer_key'] = customer_dim.index + 1\n",
    "    print(f\"Created CustomerDim with {len(customer_dim)} unique customers.\")\n",
    "    \n",
    "    # Create the Time Dimension table.\n",
    "    time_dim = pd.DataFrame(\n",
    "        df_filtered['InvoiceDate'].dt.date.unique(), columns=['date']\n",
    "    )\n",
    "    time_dim.sort_values('date', inplace=True)\n",
    "    time_dim['time_key'] = time_dim.index + 1\n",
    "    time_dim['day_of_week'] = time_dim['date'].apply(lambda x: x.strftime('%A'))\n",
    "    time_dim['month'] = time_dim['date'].apply(lambda x: x.strftime('%B'))\n",
    "    time_dim['quarter'] = time_dim['date'].apply(lambda x: pd.Timestamp(x).quarter)\n",
    "    time_dim['year'] = time_dim['date'].apply(lambda x: x.year)\n",
    "    print(f\"Created TimeDim with {len(time_dim)} unique dates.\")\n",
    "    \n",
    "    # Prepare the Fact table by merging with the dimension keys.\n",
    "    df_fact = pd.merge(df_filtered, customer_dim[['CustomerID', 'customer_key']], on='CustomerID', how='left')\n",
    "    df_fact = pd.merge(df_fact, time_dim[['date', 'time_key']], left_on=df_fact['InvoiceDate'].dt.date, right_on='date', how='left')\n",
    "    df_fact.drop(columns=['key_0', 'date'], inplace=True) # Clean up merge columns\n",
    "    \n",
    "    # Select the final columns for the Sales Fact table.\n",
    "    sales_fact = df_fact[[\n",
    "        'customer_key', \n",
    "        'time_key', \n",
    "        'Quantity', \n",
    "        'UnitPrice', \n",
    "        'TotalSales'\n",
    "    ]]\n",
    "    print(f\"Prepared SalesFact table with {len(sales_fact)} rows.\")\n",
    "    \n",
    "    print(\"Transformation complete.\")\n",
    "    return sales_fact, customer_dim, time_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b657dff6",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ad0cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(sales_fact, customer_dim, time_dim, db_name='retail_dw.db'):\n",
    "    \"\"\"\n",
    "    Loads the transformed data into a SQLite database.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Loading Phase ---\")\n",
    "    \n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    print(f\"Connected to database: {db_name}\")\n",
    "    \n",
    "    try:\n",
    "        # Drop tables if they exist to ensure a clean load.\n",
    "        cursor.execute(\"DROP TABLE IF EXISTS CustomerDim;\")\n",
    "        cursor.execute(\"DROP TABLE IF EXISTS TimeDim;\")\n",
    "        cursor.execute(\"DROP TABLE IF EXISTS SalesFact;\")\n",
    "        \n",
    "        # Create the new tables with the correct schema.\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS CustomerDim (\n",
    "                customer_key INTEGER PRIMARY KEY,\n",
    "                CustomerID TEXT NOT NULL UNIQUE,\n",
    "                total_purchases REAL,\n",
    "                country TEXT\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS TimeDim (\n",
    "                time_key INTEGER PRIMARY KEY,\n",
    "                date TEXT NOT NULL UNIQUE,\n",
    "                day_of_week TEXT,\n",
    "                month TEXT,\n",
    "                quarter INTEGER,\n",
    "                year INTEGER\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS SalesFact (\n",
    "                sales_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                customer_key INTEGER,\n",
    "                time_key INTEGER,\n",
    "                quantity INTEGER NOT NULL,\n",
    "                unit_price REAL NOT NULL,\n",
    "                total_sales REAL NOT NULL,\n",
    "                FOREIGN KEY(customer_key) REFERENCES CustomerDim(customer_key),\n",
    "                FOREIGN KEY(time_key) REFERENCES TimeDim(time_key)\n",
    "            );\n",
    "        \"\"\")\n",
    "        print(\"Database tables created.\")\n",
    "\n",
    "        # Load data from the pandas DataFrames into the SQLite tables.\n",
    "        customer_dim.to_sql('CustomerDim', conn, if_exists='append', index=False)\n",
    "        print(f\"Loaded {len(customer_dim)} rows into CustomerDim.\")\n",
    "        \n",
    "        time_dim.to_sql('TimeDim', conn, if_exists='append', index=False)\n",
    "        print(f\"Loaded {len(time_dim)} rows into TimeDim.\")\n",
    "        \n",
    "        sales_fact.to_sql('SalesFact', conn, if_exists='append', index=False)\n",
    "        print(f\"Loaded {len(sales_fact)} rows into SalesFact.\")\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"Data loading complete. Changes committed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the loading phase: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f80ced9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Extraction Phase ---\n",
      "Error during data extraction: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.\n"
     ]
    }
   ],
   "source": [
    "def run_etl():\n",
    "    \"\"\"\n",
    "    Main function to execute the full ETL process.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run the Extraction phase.\n",
    "        raw_df = extract()\n",
    "        if raw_df is None:\n",
    "            return # Exit if extraction failed\n",
    "\n",
    "        # Run the Transformation phase.\n",
    "        sales_fact_df, customer_dim_df, time_dim_df = transform(raw_df)\n",
    "        \n",
    "        # Run the Loading phase.\n",
    "        load(sales_fact_df, customer_dim_df, time_dim_df)\n",
    "        \n",
    "        print(\"\\nETL process completed successfully! ðŸŽ‰\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during the ETL process: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_etl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4f994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
