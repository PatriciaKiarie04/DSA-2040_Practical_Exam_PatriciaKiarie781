{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb7fbfb",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdafec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install openpyxl pandas --quiet\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def extract(data_source='C:\\\\Users\\\\flags\\\\End-sem DSA 2040\\\\DSA-2040_Practical_Exam_PatriciaKiarie781\\\\Data Warehousing\\\\ETL_Process\\\\raw\\\\Online Retail.xlsx'):\n",
    "    \"\"\"\n",
    "    Extracts data from an Excel file into a pandas DataFrame.\n",
    "    Handles missing values, data type conversions, and basic data validation.\n",
    "    \n",
    "    Args:\n",
    "        data_source (str): Path to the Excel file containing retail data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame or None: Cleaned DataFrame if successful, None if extraction fails\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Extraction Phase ---\")\n",
    "    \n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        df_raw = pd.read_excel(data_source)\n",
    "        print(f\"Data extracted from {data_source}. Total rows: {len(df_raw)}\")\n",
    "        \n",
    "        # Basic data validation\n",
    "        required_columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', \n",
    "                          'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']\n",
    "        missing_columns = [col for col in required_columns if col not in df_raw.columns]\n",
    "        if missing_columns:\n",
    "            print(f\"Error: Missing required columns: {missing_columns}\")\n",
    "            return None\n",
    "            \n",
    "        # Handle missing values\n",
    "        print(\"\\nMissing values before cleaning:\")\n",
    "        print(df_raw.isnull().sum())\n",
    "        \n",
    "        # Drop rows with missing CustomerID as it's crucial for the customer dimension\n",
    "        df_raw.dropna(subset=['CustomerID'], inplace=True)\n",
    "        \n",
    "        # Fill missing values for other columns\n",
    "        df_raw['Description'].fillna('Unknown Product', inplace=True)\n",
    "        df_raw['Country'].fillna('Unknown', inplace=True)\n",
    "        \n",
    "        # Convert data types\n",
    "        df_raw['CustomerID'] = df_raw['CustomerID'].astype(int)\n",
    "        df_raw['InvoiceDate'] = pd.to_datetime(df_raw['InvoiceDate'])\n",
    "        df_raw['UnitPrice'] = pd.to_numeric(df_raw['UnitPrice'], errors='coerce')\n",
    "        df_raw['Quantity'] = pd.to_numeric(df_raw['Quantity'], errors='coerce')\n",
    "        \n",
    "        # Remove rows with invalid numeric values\n",
    "        df_raw.dropna(subset=['UnitPrice', 'Quantity'], inplace=True)\n",
    "        \n",
    "        print(\"\\nMissing values after cleaning:\")\n",
    "        print(df_raw.isnull().sum())\n",
    "        print(f\"\\nFinal row count: {len(df_raw)}\")\n",
    "        print(\"\\nData types of columns:\")\n",
    "        print(df_raw.dtypes)\n",
    "        \n",
    "        print(\"\\nExtraction complete.\")\n",
    "        return df_raw\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Excel file '{data_source}' not found. Please ensure the file is in the correct directory.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data extraction: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34a3f839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Extraction Phase ---\n",
      "Data extracted from C:\\Users\\flags\\End-sem DSA 2040\\DSA-2040_Practical_Exam_PatriciaKiarie781\\Data Warehousing\\ETL_Process\\raw\\Online Retail.xlsx. Total rows: 541909\n",
      "\n",
      "Missing values before cleaning:\n",
      "InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "CustomerID     135080\n",
      "Country             0\n",
      "dtype: int64\n",
      "Data extracted from C:\\Users\\flags\\End-sem DSA 2040\\DSA-2040_Practical_Exam_PatriciaKiarie781\\Data Warehousing\\ETL_Process\\raw\\Online Retail.xlsx. Total rows: 541909\n",
      "\n",
      "Missing values before cleaning:\n",
      "InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "CustomerID     135080\n",
      "Country             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flags\\AppData\\Local\\Temp\\ipykernel_9100\\2416959743.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_raw['Description'].fillna('Unknown Product', inplace=True)\n",
      "C:\\Users\\flags\\AppData\\Local\\Temp\\ipykernel_9100\\2416959743.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_raw['Country'].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after cleaning:\n",
      "InvoiceNo      0\n",
      "StockCode      0\n",
      "Description    0\n",
      "Quantity       0\n",
      "InvoiceDate    0\n",
      "UnitPrice      0\n",
      "CustomerID     0\n",
      "Country        0\n",
      "dtype: int64\n",
      "\n",
      "Final row count: 406829\n",
      "\n",
      "Data types of columns:\n",
      "InvoiceNo              object\n",
      "StockCode              object\n",
      "Description            object\n",
      "Quantity                int64\n",
      "InvoiceDate    datetime64[ns]\n",
      "UnitPrice             float64\n",
      "CustomerID              int64\n",
      "Country                object\n",
      "dtype: object\n",
      "\n",
      "Extraction complete.\n",
      "\n",
      "Preview of the extracted and cleaned data:\n",
      "\n",
      "First 5 rows:\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0 2010-12-01 08:26:00       2.55       17850  United Kingdom  \n",
      "1 2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
      "2 2010-12-01 08:26:00       2.75       17850  United Kingdom  \n",
      "3 2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
      "4 2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 406829 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    406829 non-null  object        \n",
      " 1   StockCode    406829 non-null  object        \n",
      " 2   Description  406829 non-null  object        \n",
      " 3   Quantity     406829 non-null  int64         \n",
      " 4   InvoiceDate  406829 non-null  datetime64[ns]\n",
      " 5   UnitPrice    406829 non-null  float64       \n",
      " 6   CustomerID   406829 non-null  int64         \n",
      " 7   Country      406829 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(4)\n",
      "memory usage: 27.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Run the extraction function and display results\n",
    "import pandas as pd\n",
    "raw_data = extract()\n",
    "\n",
    "if raw_data is not None:\n",
    "    print(\"\\nPreview of the extracted and cleaned data:\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(raw_data.head())\n",
    "    \n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(raw_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c309da",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "743a227e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after dropna: 406829\n",
      "Rows after removing outliers: 397884\n",
      "InvoiceDate range: 2010-12-01 08:26:00 to 2011-12-09 12:50:00\n",
      "Rows after date filter: 0\n",
      "No rows in the last year, using most recent year in data instead.\n",
      "Rows in most recent year: 384529\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CustomerID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TotalPurchases",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d48a10af-1631-42cc-a65f-277352600c64",
       "rows": [
        [
         "0",
         "12346",
         "77183.6",
         "United Kingdom"
        ],
        [
         "1",
         "12347",
         "3598.21",
         "Iceland"
        ],
        [
         "2",
         "12348",
         "1797.24",
         "Finland"
        ],
        [
         "3",
         "12349",
         "1757.55",
         "Italy"
        ],
        [
         "4",
         "12350",
         "334.4",
         "Norway"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>TotalPurchases</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346</td>\n",
       "      <td>77183.60</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347</td>\n",
       "      <td>3598.21</td>\n",
       "      <td>Iceland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12348</td>\n",
       "      <td>1797.24</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12349</td>\n",
       "      <td>1757.55</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12350</td>\n",
       "      <td>334.40</td>\n",
       "      <td>Norway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  TotalPurchases         Country\n",
       "0       12346        77183.60  United Kingdom\n",
       "1       12347         3598.21         Iceland\n",
       "2       12348         1797.24         Finland\n",
       "3       12349         1757.55           Italy\n",
       "4       12350          334.40          Norway"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TotalSales column\n",
    "\n",
    "raw_data['TotalSales'] = raw_data['Quantity'] * raw_data['UnitPrice']\n",
    "\n",
    "print('Rows after dropna:', len(raw_data))\n",
    "\n",
    "# Remove outliers: Quantity < 0 or UnitPrice <= 0\n",
    "raw_data = raw_data[(raw_data['Quantity'] >= 0) & (raw_data['UnitPrice'] > 0)]\n",
    "print('Rows after removing outliers:', len(raw_data))\n",
    "\n",
    "# Check min and max InvoiceDate\n",
    "print('InvoiceDate range:', raw_data['InvoiceDate'].min(), 'to', raw_data['InvoiceDate'].max())\n",
    "\n",
    "# Try to filter data for sales in the last year (from 2024-08-12 to 2025-08-12)\n",
    "current_date = pd.Timestamp('2025-08-12')\n",
    "one_year_ago = current_date - pd.Timedelta(days=365)\n",
    "df_last_year = raw_data[(raw_data['InvoiceDate'] >= one_year_ago) & (raw_data['InvoiceDate'] <= current_date)]\n",
    "print('Rows after date filter:', len(df_last_year))\n",
    "\n",
    "# If no rows, use the most recent year in the data\n",
    "if df_last_year.empty:\n",
    "    print('No rows in the last year, using most recent year in data instead.')\n",
    "    max_date = raw_data['InvoiceDate'].max()\n",
    "    min_date = max_date - pd.Timedelta(days=365)\n",
    "    df_last_year = raw_data[(raw_data['InvoiceDate'] >= min_date) & (raw_data['InvoiceDate'] <= max_date)]\n",
    "    print('Rows in most recent year:', len(df_last_year))\n",
    "\n",
    "# Create customer summary: total purchases and country\n",
    "customer_summary = df_last_year.groupby('CustomerID').agg(\n",
    "    TotalPurchases=('TotalSales', 'sum'),\n",
    "    Country=('Country', 'first')\n",
    ").reset_index()\n",
    "\n",
    "# Display the first few rows of the customer summary\n",
    "customer_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b657dff6",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ad0cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(transformed_data, customer_summary, db_name='retail_dw.db'):\n",
    "    \"\"\"\n",
    "    Loads the transformed data into SQLite database with fact and dimension tables\n",
    "    \n",
    "    Args:\n",
    "        transformed_data (pd.DataFrame): The transformed sales data\n",
    "        customer_summary (pd.DataFrame): The customer dimension data\n",
    "        db_name (str): Name of the SQLite database file\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Loading Phase ---\")\n",
    "    \n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    print(f\"Connected to database: {db_name}\")\n",
    "    \n",
    "    try:\n",
    "        # Drop existing tables to ensure a clean load\n",
    "        cursor.execute(\"DROP TABLE IF EXISTS CustomerDim;\")\n",
    "        cursor.execute(\"DROP TABLE IF EXISTS TimeDim;\")\n",
    "        cursor.execute(\"DROP TABLE IF EXISTS SalesFact;\")\n",
    "        \n",
    "        # Create CustomerDim table\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE CustomerDim (\n",
    "                customer_id INTEGER PRIMARY KEY,\n",
    "                total_purchases REAL,\n",
    "                country TEXT,\n",
    "                transaction_count INTEGER\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        # Create TimeDim table\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE TimeDim (\n",
    "                date_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                date DATE,\n",
    "                year INTEGER,\n",
    "                month TEXT,\n",
    "                day_of_week TEXT\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        # Create SalesFact table\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE SalesFact (\n",
    "                sale_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                invoice_no TEXT,\n",
    "                customer_id INTEGER,\n",
    "                date_id INTEGER,\n",
    "                quantity INTEGER,\n",
    "                unit_price REAL,\n",
    "                total_sales REAL,\n",
    "                FOREIGN KEY(customer_id) REFERENCES CustomerDim(customer_id),\n",
    "                FOREIGN KEY(date_id) REFERENCES TimeDim(date_id)\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        # Prepare and load TimeDim data\n",
    "        unique_dates = transformed_data['InvoiceDate'].dt.date.unique()\n",
    "        time_data = []\n",
    "        for date in unique_dates:\n",
    "            dt = pd.Timestamp(date)\n",
    "            time_data.append((\n",
    "                date,\n",
    "                dt.year,\n",
    "                dt.strftime('%B'),\n",
    "                dt.strftime('%A')\n",
    "            ))\n",
    "        \n",
    "        cursor.executemany(\n",
    "            \"INSERT INTO TimeDim (date, year, month, day_of_week) VALUES (?, ?, ?, ?)\",\n",
    "            time_data\n",
    "        )\n",
    "        \n",
    "        # Load CustomerDim data\n",
    "        customer_data = customer_summary.to_dict('records')\n",
    "        cursor.executemany(\n",
    "            \"INSERT INTO CustomerDim (customer_id, total_purchases, country, transaction_count) VALUES (:CustomerID, :total_purchases, :country, :transaction_count)\",\n",
    "            customer_data\n",
    "        )\n",
    "        \n",
    "        # Prepare and load SalesFact data\n",
    "        # First, get the date_id mapping\n",
    "        cursor.execute(\"SELECT date_id, date FROM TimeDim\")\n",
    "        date_mapping = {str(date): id for id, date in cursor.fetchall()}\n",
    "        \n",
    "        # Prepare sales fact data\n",
    "        sales_data = []\n",
    "        for _, row in transformed_data.iterrows():\n",
    "            date_id = date_mapping[str(row['InvoiceDate'].date())]\n",
    "            sales_data.append((\n",
    "                row['InvoiceNo'],\n",
    "                int(row['CustomerID']),\n",
    "                date_id,\n",
    "                int(row['Quantity']),\n",
    "                float(row['UnitPrice']),\n",
    "                float(row['TotalSales'])\n",
    "            ))\n",
    "        \n",
    "        # Insert sales fact data\n",
    "        cursor.executemany(\n",
    "            \"INSERT INTO SalesFact (invoice_no, customer_id, date_id, quantity, unit_price, total_sales) VALUES (?, ?, ?, ?, ?, ?)\",\n",
    "            sales_data\n",
    "        )\n",
    "        \n",
    "        conn.commit()\n",
    "        \n",
    "        # Print summary\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM CustomerDim\")\n",
    "        customer_count = cursor.fetchone()[0]\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM TimeDim\")\n",
    "        time_count = cursor.fetchone()[0]\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM SalesFact\")\n",
    "        sales_count = cursor.fetchone()[0]\n",
    "        \n",
    "        print(f\"\\nLoaded successfully:\")\n",
    "        print(f\"- CustomerDim: {customer_count} rows\")\n",
    "        print(f\"- TimeDim: {time_count} rows\")\n",
    "        print(f\"- SalesFact: {sales_count} rows\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during loading: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        conn.close()\n",
    "        print(\"\\nDatabase connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f80ced9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into SQLite database: C:\\Users\\flags\\End-sem DSA 2040\\DSA-2040_Practical_Exam_PatriciaKiarie781\\Data Warehousing\\ETL_Process\\retail_dw.db\n"
     ]
    }
   ],
   "source": [
    "# Create SQLite database and load data into fact and dimension tables\n",
    "import os\n",
    "\n",
    "# Define absolute database file path\n",
    "db_dir = r'C:\\\\Users\\\\flags\\\\End-sem DSA 2040\\\\DSA-2040_Practical_Exam_PatriciaKiarie781\\\\Data Warehousing\\\\ETL_Process\\\\raw\\\\Online Retail.xlsx'\n",
    "db_path = os.path.join(db_dir, 'C:\\\\Users\\\\flags\\\\End-sem DSA 2040\\\\DSA-2040_Practical_Exam_PatriciaKiarie781\\\\Data Warehousing\\\\ETL_Process\\\\retail_dw.db')\n",
    "\n",
    "# Ensure the directory exists\n",
    "#os.makedirs(db_dir, exist_ok=True)\n",
    "\n",
    "# Remove existing database for a clean start (optional)\n",
    "#if os.path.exists(db_path):\n",
    "    #os.remove(db_path)\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Prepare CustomerDim\n",
    "customer_dim = customer_summary[['CustomerID', 'Country']].drop_duplicates().copy()\n",
    "customer_dim.to_sql('CustomerDim', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Prepare TimeDim\n",
    "time_dim = df_last_year[['InvoiceDate']].drop_duplicates().copy()\n",
    "time_dim['TimeID'] = time_dim['InvoiceDate'].astype(str)\n",
    "time_dim['Year'] = time_dim['InvoiceDate'].dt.year\n",
    "time_dim['Month'] = time_dim['InvoiceDate'].dt.month\n",
    "time_dim['Day'] = time_dim['InvoiceDate'].dt.day\n",
    "time_dim.to_sql('TimeDim', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Prepare SalesFact\n",
    "sales_fact = df_last_year[['InvoiceNo', 'StockCode', 'CustomerID', 'Quantity', 'UnitPrice', 'TotalSales', 'InvoiceDate']].copy()\n",
    "sales_fact['TimeID'] = sales_fact['InvoiceDate'].astype(str)\n",
    "sales_fact.to_sql('SalesFact', conn, index=False, if_exists='replace')\n",
    "\n",
    "conn.close()\n",
    "print(f'Data loaded into SQLite database: {db_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06b936f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ETL process...\n",
      "\n",
      "1. EXTRACTION\n",
      "\n",
      "--- Starting Extraction Phase ---\n",
      "Data extracted from C:\\Users\\flags\\End-sem DSA 2040\\DSA-2040_Practical_Exam_PatriciaKiarie781\\Data Warehousing\\ETL_Process\\raw\\Online Retail.xlsx. Total rows: 541909\n",
      "\n",
      "Missing values before cleaning:\n",
      "InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "CustomerID     135080\n",
      "Country             0\n",
      "dtype: int64\n",
      "Data extracted from C:\\Users\\flags\\End-sem DSA 2040\\DSA-2040_Practical_Exam_PatriciaKiarie781\\Data Warehousing\\ETL_Process\\raw\\Online Retail.xlsx. Total rows: 541909\n",
      "\n",
      "Missing values before cleaning:\n",
      "InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "CustomerID     135080\n",
      "Country             0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after cleaning:\n",
      "InvoiceNo      0\n",
      "StockCode      0\n",
      "Description    0\n",
      "Quantity       0\n",
      "InvoiceDate    0\n",
      "UnitPrice      0\n",
      "CustomerID     0\n",
      "Country        0\n",
      "dtype: int64\n",
      "\n",
      "Final row count: 406829\n",
      "\n",
      "Data types of columns:\n",
      "InvoiceNo              object\n",
      "StockCode              object\n",
      "Description            object\n",
      "Quantity                int64\n",
      "InvoiceDate    datetime64[ns]\n",
      "UnitPrice             float64\n",
      "CustomerID              int64\n",
      "Country                object\n",
      "dtype: object\n",
      "\n",
      "Extraction complete.\n",
      "\n",
      " ETL process failed: name 'log_etl_stats' is not defined\n",
      "Please check the error message above and try again.\n",
      "\n",
      "Missing values after cleaning:\n",
      "InvoiceNo      0\n",
      "StockCode      0\n",
      "Description    0\n",
      "Quantity       0\n",
      "InvoiceDate    0\n",
      "UnitPrice      0\n",
      "CustomerID     0\n",
      "Country        0\n",
      "dtype: int64\n",
      "\n",
      "Final row count: 406829\n",
      "\n",
      "Data types of columns:\n",
      "InvoiceNo              object\n",
      "StockCode              object\n",
      "Description            object\n",
      "Quantity                int64\n",
      "InvoiceDate    datetime64[ns]\n",
      "UnitPrice             float64\n",
      "CustomerID              int64\n",
      "Country                object\n",
      "dtype: object\n",
      "\n",
      "Extraction complete.\n",
      "\n",
      " ETL process failed: name 'log_etl_stats' is not defined\n",
      "Please check the error message above and try again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flags\\AppData\\Local\\Temp\\ipykernel_9100\\2416959743.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_raw['Description'].fillna('Unknown Product', inplace=True)\n",
      "C:\\Users\\flags\\AppData\\Local\\Temp\\ipykernel_9100\\2416959743.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_raw['Country'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Run the ETL process with detailed logging\n",
    "run_etl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5028ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_etl_stats(stage, description, row_count, additional_info=None):\n",
    "    \"\"\"\n",
    "    Log statistics for each ETL stage\n",
    "    \n",
    "    Args:\n",
    "        stage (str): ETL stage name (Extract, Transform, or Load)\n",
    "        description (str): Description of the specific operation\n",
    "        row_count (int): Number of rows processed\n",
    "        additional_info (dict, optional): Any additional metrics to log\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"\\n[{timestamp}] {stage} - {description}\")\n",
    "    print(f\"Rows processed: {row_count:,}\")\n",
    "    \n",
    "    if additional_info:\n",
    "        print(\"Additional metrics:\")\n",
    "        for key, value in additional_info.items():\n",
    "            print(f\"- {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
